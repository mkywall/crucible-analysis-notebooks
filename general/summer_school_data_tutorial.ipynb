{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkywall/crucible-analysis-notebooks/blob/main/general/summer_school_data_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__Y4pqvXUsg0"
      },
      "source": [
        "# Crucible Tutorial\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCDbZ9ny44Y4"
      },
      "source": [
        "## Part 1: Setup\n",
        "- Install the crucible python client\n",
        "- Import packages\n",
        "- Retrieve your personal Crucible API key\n",
        "- Initialize your client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBDo9mng5HP7"
      },
      "source": [
        "#### Install the client from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pK7EG7WzU948"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/MolecularFoundryCrucible/pycrucible.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5kwj7Sb5L5A"
      },
      "source": [
        "#### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1qADdHnUsg3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pprint\n",
        "import uuid\n",
        "from typing import List, Dict\n",
        "from datetime import datetime\n",
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pycrucible import CrucibleClient, SecureInput"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCeMlmoA5W_V"
      },
      "source": [
        "#### Retrieve your API key\n",
        "\n",
        "In your web browser navigate to https://crucible.lbl.gov/testapi/user_apikey.\n",
        "\n",
        "You will be prompted to login to your ORCID.  Login.\n",
        "\n",
        "Run the cell below and copy your resulting API key into the box!\n",
        "\n",
        "** note: If you do not have an ORCID you can easily create one here: https://orcid.org/register"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRinTqFl53wM"
      },
      "outputs": [],
      "source": [
        "SecureInput(description = \"Enter your API key:\", var_name = 'CRUCIBLE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ-kL4_1Usg4"
      },
      "source": [
        "#### Initialize the client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwleG71nUsg4"
      },
      "outputs": [],
      "source": [
        "API_URL = \"https://crucible.lbl.gov/testapi\"\n",
        "API_KEY = os.environ.get(\"CRUCIBLE_API_KEY\")\n",
        "\n",
        "# Initialize the client\n",
        "client = CrucibleClient(API_URL, API_KEY)\n",
        "print(\"Crucible client initialized successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajyxgack6P7s",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## Part 2: Use the client to work with a batch of perovskite data\n",
        "For this demo we will be using data generated for a batch of perovskite wafers generated by Yi-Ru.  The batch is named `S-pMeMBAI-pre-2` and has the unique id: `0t3h7ymbm5s27000z6tt82zvx4`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HKTnghd7VBs"
      },
      "source": [
        "##### Query the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9PQoNS363gq"
      },
      "outputs": [],
      "source": [
        "# set the batch_id as a variable\n",
        "batch_id = '0t3h7ymbm5s27000z6tt82zvx4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sg0goib666wS",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# list all of the samples associated with this batch\n",
        "client.list_samples(parent_id = batch_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNnX2tqV6-zS",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# list all of the datasets associated with this batch\n",
        "client.list_datasets(sample_id = batch_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOwOJYSv7YUZ"
      },
      "source": [
        "##### Download data files\n",
        "\n",
        "After running the following cell, you can to navigate to the file system on the right by clicking the folder icon.  You should see a folder titled \"crucible_downloads\" that will contain all of the files you just downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQQrxcl37bqI"
      },
      "outputs": [],
      "source": [
        "batch_datasets = client.list_datasets(sample_id = batch_id)[0:2]\n",
        "for ds in batch_datasets:\n",
        "    pprint.pprint(ds)\n",
        "    try:\n",
        "      client.download_dataset(dsid = ds['unique_id'])\n",
        "      print('downloaded')\n",
        "    except Exception as err:\n",
        "      print(err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaLEaNny70iC"
      },
      "source": [
        "## Part 3: Working with ScopeFoundry hdf5 files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CLniWAa622z"
      },
      "source": [
        "### Open the file and get your bearings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_5IvGWA622z"
      },
      "outputs": [],
      "source": [
        "# Choose a file to work with\n",
        "sample_file = 'crucible-downloads/yrliu98_S-pMeMBAI-pre-2_1_1_run3_spec_run.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6swDWG3622z"
      },
      "outputs": [],
      "source": [
        "# Opening the file\n",
        "with h5py.File(sample_file, 'r') as f:\n",
        "  # groups within the file object\n",
        "  print(f.keys())\n",
        "\n",
        "  # attributes of the file object (the file object is the \"root group\")\n",
        "  print(f.attrs.keys())\n",
        "\n",
        "  # every group has a name (the name is the key)\n",
        "  for group_name in f:\n",
        "    print(group_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFK80HUN622z"
      },
      "outputs": [],
      "source": [
        "# The App Group\n",
        "\n",
        "with h5py.File(sample_file, 'r') as f:\n",
        "  app = f['app']\n",
        "\n",
        "  # groups within the app group\n",
        "  print(list(app.keys()))\n",
        "\n",
        "  # attributes of the app group\n",
        "  print(list(app.attrs.keys()))\n",
        "\n",
        "  # print the settings group attributes for the app\n",
        "  print(\"\\n\\napp settings: \")\n",
        "  [print(k,v) for k,v in list(app['settings'].attrs.items())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjmuXW-U622z"
      },
      "outputs": [],
      "source": [
        "# The Hardware Group\n",
        "\n",
        "with h5py.File(sample_file, 'r') as f:\n",
        "  hw = f['hardware']\n",
        "\n",
        "  # groups within the hw group\n",
        "  print(list(hw.keys()))\n",
        "\n",
        "  # attributes of the hw group\n",
        "  print(list(hw.attrs.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73qvO3DS6220"
      },
      "outputs": [],
      "source": [
        "# The Measurement Group\n",
        "\n",
        "with h5py.File(sample_file, 'r') as f:\n",
        "  M = f['measurement']\n",
        "\n",
        "  # groups within the measurement group\n",
        "  print(list(M.keys()))\n",
        "\n",
        "  # attributes of the measurement group\n",
        "  print(list(M.attrs.keys()))\n",
        "\n",
        "  # Look at the measurement sub group\n",
        "  # Note that you can keep extending out key values for groups or use a file system like notation\n",
        "  print(list(f['measurement']['spec_run'].keys()))\n",
        "  print(list(f['measurement/spec_run'].keys()))\n",
        "\n",
        "  # Each of the values printed is a Dataset Object that can be accessed as a numpy array\n",
        "  arr = np.array(f['measurement/spec_run/wl_spectra'])\n",
        "  print(arr[0:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8pWckmd6220"
      },
      "source": [
        "### Recurse the file systematically with the ```visititems``` function.\n",
        "Instead of manually recursing the file, we can define a function and pass it to visititems which will recursively call the function on each of the objects in the h5file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDXBlM7l6220"
      },
      "outputs": [],
      "source": [
        "def explore_h5_structure(name, obj):\n",
        "    indent = \"  \" * name.count('/')\n",
        "    if isinstance(obj, h5py.Group):\n",
        "        print(f\"{indent}{name}/ (Group)\")\n",
        "    elif isinstance(obj, h5py.Dataset):\n",
        "        print(f\"{indent}{name} (Dataset) - Shape: {obj.shape}, Type: {obj.dtype}\")\n",
        "\n",
        "with h5py.File(sample_file, 'r') as f:\n",
        "    f.visititems(explore_h5_structure)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gyEdMmF6220"
      },
      "source": [
        "### Extract and plot the PL spectra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7GXcFEP6220"
      },
      "outputs": [],
      "source": [
        "with h5py.File(sample_file, 'r') as h5file:\n",
        "\n",
        "    # extract the corrected PL spectra as an array\n",
        "    pl_spectra = np.array(h5file['measurement/spec_run/pl_spectra_corrected'])\n",
        "\n",
        "    # determine how many spectra were collected\n",
        "    dims = pl_spectra.shape\n",
        "\n",
        "    # extract the wavelengths as an array\n",
        "    wavelengths = np.array(h5file['measurement/spec_run/pl_wls'])\n",
        "\n",
        "    # create the plot\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # for each spectra, plot the line\n",
        "    for i in range(0, dims[0]):\n",
        "        ax.plot(wavelengths, pl_spectra[i], label=f\"Spectrum {i+1}\", linewidth=2, alpha=0.8)\n",
        "\n",
        "    # formatting\n",
        "    ax.set_xlabel('Wavelength (nm)', fontsize=12)\n",
        "    ax.set_ylabel('Intensity', fontsize=12)\n",
        "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMhaYekF6220"
      },
      "source": [
        "### Extract and plot the UV-vis spectra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQ_n1beB6220"
      },
      "outputs": [],
      "source": [
        "with h5py.File(sample_file, 'r') as h5file:\n",
        "\n",
        "    # extract the corrected PL spectra as an array\n",
        "    wl_spectra = np.array(h5file['measurement/spec_run/wl_spectra_corrected'])\n",
        "\n",
        "    # determine how many spectra were collected\n",
        "    dims = wl_spectra.shape\n",
        "\n",
        "    # extract the wavelengths as an array\n",
        "    wavelengths = np.array(h5file['measurement/spec_run/wl_wls'])\n",
        "\n",
        "    # create the plot\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # for each spectra, plot the line\n",
        "    for i in range(0, dims[0]):\n",
        "        ax.plot(wavelengths, wl_spectra[i], label=f\"Spectrum {i+1}\", linewidth=2, alpha=0.8)\n",
        "\n",
        "    # formatting\n",
        "    ax.set_xlabel('Wavelength (nm)', fontsize=12)\n",
        "    ax.set_ylabel('Intensity', fontsize=12)\n",
        "    ax.set_ylim(0,1)\n",
        "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7BqcD1Q6220"
      },
      "source": [
        "### Extract and display the sample image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDJRmqhy6220"
      },
      "outputs": [],
      "source": [
        "with h5py.File(sample_file, 'r') as h5file:\n",
        "\n",
        "    # extract the image\n",
        "    imarray = np.array(h5file['measurement/spec_run/adj_photo'])\n",
        "\n",
        "    # create the plot\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    ax.imshow(imarray, cmap = 'grey')\n",
        "    ax.set_title('Sample Photo', fontsize=14, fontweight='bold')\n",
        "    ax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qmc8y2I6220"
      },
      "source": [
        "### Scale this to explore the whole batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYj4Rtuf6220"
      },
      "source": [
        "#### Define functions for extracting the data and creating the plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Opf7yqQkIdnU"
      },
      "outputs": [],
      "source": [
        "# Spectra plotting\n",
        "def make_spectra_plot(M, s, w, title=\"\"):\n",
        "    \"\"\"Create a spectra plot with proper formatting\"\"\"\n",
        "    if len(M[s]) > 0:\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        spectra = np.array(M[s])\n",
        "        dims = spectra.shape\n",
        "        wls = np.array(M[w])\n",
        "\n",
        "        for i in range(0, dims[0]):\n",
        "            ax.plot(wls, spectra[i], label=f\"Spectrum {i+1}\", linewidth=2, alpha=0.8)\n",
        "\n",
        "        ax.set_xlabel('Wavelength (nm)', fontsize=12)\n",
        "        ax.set_ylabel('Intensity', fontsize=12)\n",
        "        if 'wl' in s:\n",
        "            ax.set_ylim(0,1)\n",
        "\n",
        "        ax.set_title(f'{title} Spectra', fontsize=14, fontweight='bold')\n",
        "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "    return None\n",
        "\n",
        "\n",
        "# Generalized plot generator\n",
        "def get_sample_plots(specrun_file):\n",
        "    \"\"\"Extract data and create plots for a sample\"\"\"\n",
        "    plots = {}\n",
        "\n",
        "    with h5py.File(specrun_file, 'r') as h5file:\n",
        "        M = h5file[f\"measurement/spec_run\"]\n",
        "\n",
        "        # Create spectra plots\n",
        "        for m in list(M.keys()):\n",
        "            if m.endswith(\"spectra_corrected\"):\n",
        "                dtype = m.split(\"_\")[0]\n",
        "                wl_key = f'{dtype}_wls'\n",
        "                if wl_key in M.keys():\n",
        "                    fig = make_spectra_plot(M, m, wl_key, dtype.title())\n",
        "                    if fig:\n",
        "                        plots[m] = fig\n",
        "                        plt.close(fig)\n",
        "\n",
        "        # Handle photo data\n",
        "        if 'adj_photo' in list(M.keys()):\n",
        "            fig, ax = plt.subplots(figsize=(8, 6))\n",
        "            imarray = np.array(M['adj_photo'])\n",
        "            ax.imshow(imarray)\n",
        "            ax.set_title('Sample Photo', fontsize=14, fontweight='bold')\n",
        "            ax.axis('off')\n",
        "            plots['adj_photo'] = fig\n",
        "            plt.close(fig)\n",
        "\n",
        "    return plots\n",
        "\n",
        "\n",
        "# Graphics Formatting and switching between plots interactively\n",
        "def display_plots_by_type(plot_type):\n",
        "    \"\"\"Display all samples for a specific plot type\"\"\"\n",
        "    with output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        # Find all samples that have this plot type\n",
        "        samples_with_plot = []\n",
        "        for ds_name, plot_data in batch_sample_data.items():\n",
        "            if ('plots' in plot_data and\n",
        "                'error' not in plot_data and\n",
        "                plot_type in plot_data['plots']):\n",
        "                samples_with_plot.append((ds_name, plot_data['plots'][plot_type]))\n",
        "\n",
        "        n_samples = len(samples_with_plot)\n",
        "        cols = min(3, n_samples)\n",
        "        rows = (n_samples + cols - 1) // cols\n",
        "\n",
        "        fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))\n",
        "        fig.suptitle(f'{plot_type.replace(\"_\", \" \").title()} Comparison Across Samples',\n",
        "                     fontsize=16, fontweight='bold')\n",
        "\n",
        "        # Handle single row/column cases\n",
        "        if rows == 1 and cols == 1:\n",
        "            axes = [axes]\n",
        "        elif rows == 1 or cols == 1:\n",
        "            axes = axes.flatten() if hasattr(axes, 'flatten') else [axes]\n",
        "        else:\n",
        "            axes = axes.flatten()\n",
        "\n",
        "        # Plot each sample\n",
        "        for i, (ds_name, plot_fig) in enumerate(samples_with_plot):\n",
        "            ax = axes[i]\n",
        "\n",
        "            if plot_type == 'adj_photo':\n",
        "                # For photo data, we need to extract the image data\n",
        "                try:\n",
        "                    # Get the image data from the original plot\n",
        "                    img_data = plot_fig.axes[0].images[0].get_array()\n",
        "                    ax.imshow(img_data, cmap = 'grey')\n",
        "                    ax.set_title(f'{ds_name}', fontsize=12, fontweight='bold')\n",
        "                    ax.axis('off')\n",
        "                except Exception as e:\n",
        "                    ax.text(0.5, 0.5, f'Error displaying\\n {ds_name}',\n",
        "                           ha='center', va='center', transform=ax.transAxes)\n",
        "                    ax.set_title(f'{ds_name}', fontsize=12)\n",
        "            else:\n",
        "                #For spectra data, copy the plot lines\n",
        "                try:\n",
        "                    original_ax = plot_fig.axes[0]\n",
        "                    for line in original_ax.get_lines():\n",
        "                        ax.plot(line.get_xdata(), line.get_ydata(),\n",
        "                               label=line.get_label(), alpha=0.8)\n",
        "\n",
        "                    ax.set_xlabel(original_ax.get_xlabel())\n",
        "                    ax.set_ylabel(original_ax.get_ylabel())\n",
        "                    ax.set_title(f'{ds_name}', fontsize=12, fontweight='bold')\n",
        "                    ax.grid(True, alpha=0.3)\n",
        "\n",
        "                    # Add legend if there are multiple lines\n",
        "                    if len(original_ax.get_lines()) > 1:\n",
        "                        ax.legend(fontsize=8)\n",
        "\n",
        "                except Exception as e:\n",
        "                    ax.text(0.5, 0.5, f'Error displaying\\n {ds_name}',\n",
        "                           ha='center', va='center', transform=ax.transAxes)\n",
        "                    ax.set_title(f'{ds_name}', fontsize=12)\n",
        "\n",
        "        # Hide unused subplots\n",
        "        for i in range(n_samples, len(axes)):\n",
        "            axes[i].set_visible(False)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1Xwpi6z6221"
      },
      "source": [
        "#### Extract the data for your batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEUTxZUBiqZq"
      },
      "outputs": [],
      "source": [
        "# Process all samples and create organized data structure\n",
        "batch_sample_data = {}\n",
        "\n",
        "for i, ds in enumerate(batch_datasets[0:2]):\n",
        "    data_file = os.path.join('crucible-downloads/', os.path.basename(ds['file_to_upload']))\n",
        "    dataset_name = ds['dataset_name']\n",
        "\n",
        "    if data_file.endswith('.h5'):\n",
        "        sample_plots = get_sample_plots(data_file)\n",
        "        batch_sample_data[dataset_name] = {\n",
        "            'dataset_info': ds,\n",
        "            'plots': sample_plots,\n",
        "            'data_file': data_file\n",
        "        }\n",
        "\n",
        "\n",
        "    elif data_file.endswith('.jpg'):\n",
        "        print(f\"  - Found batch photo: {data_file}\")\n",
        "        batch_photo_file = data_file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlU6hRIL6221"
      },
      "source": [
        "### Explore the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSV01qss6221"
      },
      "outputs": [],
      "source": [
        "# Organize data by plot type for easy comparison\n",
        "plot_types_available = ['adj_photo', 'wl_spectra_corrected', 'pl_spectra_corrected']\n",
        "\n",
        "\n",
        "# Create the interactive widget\n",
        "plot_type_dropdown = widgets.Dropdown(\n",
        "    options=plot_types_available,\n",
        "    value=plot_types_available[0] if plot_types_available else None,\n",
        "    description='Plot Type:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_plot_type_change(change):\n",
        "    display_plots_by_type(change['new'])\n",
        "\n",
        "plot_type_dropdown.observe(on_plot_type_change, names='value')\n",
        "\n",
        "display(plot_type_dropdown)\n",
        "display(output)\n",
        "\n",
        "# Show the first plot type by default\n",
        "if plot_types_available:\n",
        "    display_plots_by_type(plot_types_available[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZn5ieGVUsg7"
      },
      "source": [
        "###  Part 4: Play around and see what else you can do with the API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjcKcCRPUsg7"
      },
      "source": [
        "#### Add a project you are working on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uMDP1vGUsg7"
      },
      "outputs": [],
      "source": [
        "help(client.add_project)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QmoASXYUsg7"
      },
      "outputs": [],
      "source": [
        "client.add_project(project_info = {\"project_id\":\"AUM_DEMO\",\n",
        "                                   \"organization\":\"Summer School\",\n",
        "                                   \"project_lead_email\":\"mkwall@lbl.gov\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6Fkb0_1Usg7"
      },
      "source": [
        "#### Add a sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9L-4rdo8X8q"
      },
      "outputs": [],
      "source": [
        "sample = client.add_sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THLhi7sd8a4X"
      },
      "source": [
        "#### Add a dataset from your google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kngvnFsu8gvw"
      },
      "outputs": [],
      "source": [
        "# mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJOrjY-nUsg7"
      },
      "outputs": [],
      "source": [
        "# choose a file\n",
        "your_file_path = \"sample_data/california_housing_train.csv\"\n",
        "\n",
        "# define some metadata you want to add to this dataset\n",
        "metadata_to_add = {'comments': 'this is a fake dataset',\n",
        "                   'weather': 'sunny',\n",
        "                   'iphone_version': 11\n",
        "                  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZ1xOPQ0Usg7"
      },
      "outputs": [],
      "source": [
        "# fill out the fields and send the data to Crucible\n",
        "results = client.build_new_dataset_from_file(files_to_upload = [your_file_path],\n",
        "                                        dataset_name = None, # this will default to the file name\n",
        "                                        project_id = None, # this will default to unknown\n",
        "                                        instrument_name = None, # default is null\n",
        "                                        measurement = None, # default is null\n",
        "                                        session_name = None, # default is null\n",
        "                                        source_folder = None, # this will default to the base directory\n",
        "                                        scientific_metadata = metadata_to_add, # this is the dictionary you defined above\n",
        "                                        keywords = [], # list any keywords you want to be able to search on\n",
        "                                        ingestor = 'CrucibleDatasetIngestor', # use a generic ingestor\n",
        "                                        verbose = False,\n",
        "                                        wait_for_ingestion_response = True)\n",
        "\n",
        "ds = results['created_record']\n",
        "pprint.pprint(ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fIC3B0TUsg7"
      },
      "source": [
        "#### Associate this dataset with the sample you created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_pubuDVUsg7"
      },
      "outputs": [],
      "source": [
        "# define the dataset and sample\n",
        "dataset_id = ds['unique_id']\n",
        "sample_id = sample['unique_id']\n",
        "\n",
        "# link them!\n",
        "client.add_dataset_to_sample(dataset_id = dataset_id, sample_id = sample_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5UttaWSUsg8"
      },
      "outputs": [],
      "source": [
        "# see all the datasets associated with your sample\n",
        "client.list_datasets(sample_id = sample_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8K9JcCZ9sdX"
      },
      "source": [
        "#### Send your dataset from Crucible to SciCat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsL0L90KUsg7"
      },
      "outputs": [],
      "source": [
        "client.send_to_scicat(dsid = ds['unique_id'], wait_for_scicat_response= True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVQiRWYmUsg7"
      },
      "source": [
        "Go to https://mf-scicat.lbl.gov to get a quick look at your data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "DZn5ieGVUsg7"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}