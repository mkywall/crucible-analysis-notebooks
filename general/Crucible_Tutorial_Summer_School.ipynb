{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkywall/crucible-analysis-notebooks/blob/main/general/Crucible_Tutorial_Summer_School.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__Y4pqvXUsg0"
      },
      "source": [
        "# Pycrucible Tutorial\n",
        "\n",
        "This tutorial demonstrates how to use the pycrucible client to manage data through the Crucible Platform:\n",
        "- Retrieve your user crucible API key\n",
        "- Upload datasets to Crucible with automated metadata parsing\n",
        "- Upload datasets to Crucible with manually curated metadata appended\n",
        "- Associate datasets with batches\n",
        "- Query datasets by batch, sample\n",
        "- Query samples by batch, dataset\n",
        "- Upload sample synthesis metadata\n",
        "- Download data\n",
        "- Generate AutoBot batch report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/MolecularFoundryCrucible/pycrucible.git"
      ],
      "metadata": {
        "id": "pK7EG7WzU948"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1qADdHnUsg3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from pycrucible import CrucibleClient\n",
        "import uuid\n",
        "from typing import List, Dict\n",
        "import pprint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mLvK9tncU8YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ-kL4_1Usg4"
      },
      "source": [
        "#### Step 1: Set up the Crucible Python Client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAE3oOLJUsg4"
      },
      "source": [
        "In a web browser navigate to https://crucible.lbl.gov/testapi/user_apikey.  You will be prompted to login with your ORCID.  Login to ORCID and copy the resulting apikey to an environment variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwleG71nUsg4"
      },
      "outputs": [],
      "source": [
        "# Configuration - Update these with your credentials\n",
        "API_URL = \"https://crucible.lbl.gov/testapi\"  # Replace with your API URL\n",
        "API_KEY = ''\n",
        "\n",
        "# Initialize the client\n",
        "client = CrucibleClient(API_URL, API_KEY)\n",
        "print(\"Crucible client initialized successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiFfL0YVUsg5"
      },
      "source": [
        "#### Step 2: Use the Crucible python client to upload and ingest a batch of SpecRun datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2q9eCymtUsg5"
      },
      "outputs": [],
      "source": [
        "data_folder = \"drive/Shareddrives/robot summer school/summer-school-sample-data/cbox\"\n",
        "h5_files = [f for f in os.listdir(data_folder) if f.endswith('spec_run.h5')]\n",
        "print(h5_files)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for h5file in h5_files[0:1]:\n",
        "    h5 = os.path.join(data_folder, h5file)\n",
        "    print(h5)\n",
        "    results = client.build_new_dataset_from_file(files_to_upload = [h5],\n",
        "                                            ingestor = \"SpinbotSpecRunIngestor\",\n",
        "                                            verbose = False)"
      ],
      "metadata": {
        "id": "DwTPFfFsWONl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = results['created_record']"
      ],
      "metadata": {
        "id": "JM_xhPFHWw2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIt0lI-wUsg5"
      },
      "source": [
        "##### Check out the data you just uploaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cxdXhh8aUsg6"
      },
      "outputs": [],
      "source": [
        "found_ds = client.get_dataset(ds['unique_id'], include_metadata=True)\n",
        "pprint.pprint(found_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTXyZerjUsg6"
      },
      "outputs": [],
      "source": [
        "# should make a client func for ingesting from dsid\n",
        "client.list_datasets(file_to_upload = ds['file_to_upload'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpgV-nI3Usg6"
      },
      "outputs": [],
      "source": [
        "# query by dataset\n",
        "client.list_samples(dataset_id = ds['unique_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSAs-B-DUsg6"
      },
      "outputs": [],
      "source": [
        "batch_id = '0t3h7ymbm5s27000z6tt82zvx4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "taZG1WJxUsg6"
      },
      "outputs": [],
      "source": [
        "# query by batch id\n",
        "client.list_samples(parent_id = batch_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "y1yBKs6zUsg7"
      },
      "outputs": [],
      "source": [
        "# see all datasets for a batch\n",
        "client.list_datasets(sample_id = batch_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZn5ieGVUsg7"
      },
      "source": [
        "#### Step 3: Send the dataset information to the data catalog (SciCat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsL0L90KUsg7"
      },
      "outputs": [],
      "source": [
        "client.send_to_scicat(dsid = ds['unique_id'], wait_for_scicat_response= True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVQiRWYmUsg7"
      },
      "source": [
        "Go to https://mf-scicat.lbl.gov to get a quick look at your data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjcKcCRPUsg7"
      },
      "source": [
        "##### Add a project to associate with your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uMDP1vGUsg7"
      },
      "outputs": [],
      "source": [
        "help(client.add_project)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6QmoASXYUsg7"
      },
      "outputs": [],
      "source": [
        "client.add_project(project_info = {\"project_id\":\"AUM_DEMO\",\n",
        "                                   \"organization\":\"Summer School\",\n",
        "                                   \"project_lead_email\":\"mkwall@lbl.gov\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6Fkb0_1Usg7"
      },
      "source": [
        "#### Step 4: Use the Crucible python client to upload and ingest a photo of the batch as a dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJOrjY-nUsg7"
      },
      "outputs": [],
      "source": [
        "metadata_to_add = {'comments': 'this is a fake dataset',\n",
        "                   'weather': 'sunny',\n",
        "                   'iphone_version': 11\n",
        "                  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZ1xOPQ0Usg7"
      },
      "outputs": [],
      "source": [
        "batch_name = 'S-pMeMBAI-pre-2'\n",
        "data_folder = \"drive/Shareddrives/robot summer school/summer-school-sample-data/photo_capture\"\n",
        "p1 = os.path.join(data_folder, 'DSC_0001.jpg')\n",
        "p2 = os.path.join(data_folder, 'DSC_0002.jpg')\n",
        "results = client.build_new_dataset_from_file(files_to_upload = [p1, p2],\n",
        "                                        dataset_name = 'S-pMeMBAI-pre-photo-capture',\n",
        "                                        project_id = \"AUM_DEMO\",\n",
        "                                        owner_orcid = None,\n",
        "                                        instrument_name = \"PhotoBox\",\n",
        "                                        measurement = \"iphone_capture\",\n",
        "                                        session_name = 'S-pMeMBAI-pre-2',\n",
        "                                        creation_time = None,\n",
        "                                        source_folder = data_folder,\n",
        "                                        scientific_metadata = metadata_to_add,\n",
        "                                        keywords = [batch_name],\n",
        "                                        ingestor = 'ImageIngestor',\n",
        "                                        verbose = False,\n",
        "                                        wait_for_ingestion_response = True)\n",
        "\n",
        "ds = results['created_record']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fIC3B0TUsg7"
      },
      "source": [
        "#### Step 4: Link this new dataset to the batch it is associated with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_pubuDVUsg7"
      },
      "outputs": [],
      "source": [
        "client.add_dataset_to_sample(dataset_id = ds['unique_id'], sample_id = batch_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "m5UttaWSUsg8"
      },
      "outputs": [],
      "source": [
        "client.list_datasets(sample_id = batch_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_WZGSfAUsg8"
      },
      "source": [
        "#### Step 5: Add Additional Metadata to Samples\n",
        "\n",
        "Demonstrate how to add custom metadata to individual samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "topX6rG-Usg8"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "class SpinbotBatchMetadata(BaseModel):\n",
        "    sample_id: str\n",
        "    sample_type: str = 'spinbot_batch'\n",
        "    spin_duration_s: int\n",
        "    spin_velocity_rpm: int\n",
        "    dispense_delay_s: int\n",
        "    pipette_height_mm: float\n",
        "    dispense_speed_ul_s: int\n",
        "    precursor_b_volume_ul: float\n",
        "    annealing_duration_s: int\n",
        "    molar_ratio_fai_macl: str"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_metadata = SpinbotBatchMetadata(sample_id= batch_id,\n",
        "                                       spin_duration_s = 40,\n",
        "                                       spin_velocity_rpm = 200,\n",
        "                                       dispense_delay_s = 2,\n",
        "                                       pipette_height_mm = 0.4,\n",
        "                                       dispense_speed_ul_s = 4,\n",
        "                                       precursor_b_volume_ul = 50,\n",
        "                                       annealing_duration_s = 45,\n",
        "                                       molar_ratio_fai_macl= '5:1')\n",
        "batch_metadata"
      ],
      "metadata": {
        "id": "QdNJcbs9l84F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.add_sample_metadata(**batch_metadata.model_dump())"
      ],
      "metadata": {
        "id": "XOe_qKwPnBGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2lUTEhAUsg8"
      },
      "source": [
        "#### Step 7: Download the data associated with a batch\n",
        "\n",
        "Download all datasets associated with a batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lu3k-7UGUsg8"
      },
      "outputs": [],
      "source": [
        "datasets_in_batch = client.list_datasets(sample_id = batch_id)\n",
        "print(datasets_in_batch)\n",
        "for ds in datasets_in_batch:\n",
        "    print(ds)\n",
        "    try:\n",
        "      client.download_dataset(dsid = ds['unique_id'])\n",
        "      print('downloaded')\n",
        "    except Exception as err:\n",
        "      print(err)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the batch metadata"
      ],
      "metadata": {
        "id": "a0qaponrokQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_md = client.get_sample_metadata(sample_id = batch_id)"
      ],
      "metadata": {
        "id": "6b89U5ZconFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eluHeMeZUsg8"
      },
      "source": [
        "#### Step 8: Generate a Batch Report Card"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgwjYxgmUsg8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PdAjWqg9aPGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### TO DO\n",
        "\n",
        "\n",
        "1. modify get_or_add_project to accept project_info\n",
        "2. add project having some issues in scicat when project doesn't already exist...\n",
        "3. swap get_or_add for add_project\n",
        "\n",
        "5. make sure download works\n",
        "6. sample synthesis table and upload\n",
        "    *   from xml\n",
        "7. batch report\n",
        "9. add open in colab button"
      ],
      "metadata": {
        "id": "LmU8b6qAawx5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k_P2G4DFo4Jf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}