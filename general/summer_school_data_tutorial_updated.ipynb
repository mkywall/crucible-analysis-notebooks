{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkywall/crucible-analysis-notebooks/blob/main/general/summer_school_data_tutorial_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__Y4pqvXUsg0"
      },
      "source": [
        "# Crucible Tutorial\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCDbZ9ny44Y4"
      },
      "source": [
        "## Part 1: Setup\n",
        "- Install the crucible python client\n",
        "- Import packages\n",
        "- Retrieve your personal Crucible API key\n",
        "- Initialize your client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBDo9mng5HP7"
      },
      "source": [
        "#### Install the client from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pK7EG7WzU948"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/MolecularFoundryCrucible/pycrucible.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5kwj7Sb5L5A"
      },
      "source": [
        "#### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1qADdHnUsg3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pprint\n",
        "import uuid\n",
        "from typing import List, Dict\n",
        "from datetime import datetime\n",
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pycrucible import CrucibleClient, SecureInput"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCeMlmoA5W_V"
      },
      "source": [
        "#### Retrieve your API key\n",
        "\n",
        "In your web browser navigate to https://crucible.lbl.gov/testapi/user_apikey.\n",
        "\n",
        "You will be prompted to login to your ORCID.  Login.\n",
        "\n",
        "Run the cell below and copy your resulting API key into the box!\n",
        "\n",
        "** note: If you do not have an ORCID you can easily create one here: https://orcid.org/register"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRinTqFl53wM"
      },
      "outputs": [],
      "source": [
        "SecureInput(description = \"Enter your API key:\", var_name = 'CRUCIBLE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ-kL4_1Usg4"
      },
      "source": [
        "#### Initialize the client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwleG71nUsg4"
      },
      "outputs": [],
      "source": [
        "API_URL = \"https://crucible.lbl.gov/testapi\"\n",
        "API_KEY = os.environ.get(\"CRUCIBLE_API_KEY\")\n",
        "\n",
        "# Initialize the client\n",
        "client = CrucibleClient(API_URL, API_KEY)\n",
        "print(\"Crucible client initialized successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajyxgack6P7s",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## Part 2: Use the client to work with a batch of perovskite data\n",
        "For this demo we will be using data generated for a batch of perovskite wafers generated by Yi-Ru.  The batch is named `S-pMeMBAI-pre-2` and has the unique id: `0t3h7ymbm5s27000z6tt82zvx4`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HKTnghd7VBs"
      },
      "source": [
        "##### Query the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9PQoNS363gq"
      },
      "outputs": [],
      "source": [
        "# set the batch_id as a variable\n",
        "batch_id = '0t3h7ymbm5s27000z6tt82zvx4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sg0goib666wS",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# list all of the samples associated with this batch\n",
        "client.list_samples(parent_id = batch_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNnX2tqV6-zS",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# list all of the datasets associated with this batch\n",
        "batch_datasets = client.list_datasets(sample_id = batch_id)\n",
        "print(f\"There are {len(batch_datasets)} datasets associated with this batch\")\n",
        "print(\"The first dataset is:\")\n",
        "pprint.pprint(batch_datasets[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOwOJYSv7YUZ"
      },
      "source": [
        "##### Download data files\n",
        "\n",
        "After running the following cell, you can to navigate to the file system on the right by clicking the folder icon.  You should see a folder titled \"crucible_downloads\" that will contain all of the files you just downloaded."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.get_dataset('0t4tnkawshrcz000235d01sxqw')"
      ],
      "metadata": {
        "id": "SXYysavBxpgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQQrxcl37bqI",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "\n",
        "for ds in batch_datasets:\n",
        "    pprint.pprint(ds)\n",
        "    # try:\n",
        "    client.download_dataset(dsid = ds['unique_id'])\n",
        "    print('downloaded')\n",
        "    # except Exception as err:\n",
        "    #   print(err)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import Parallel, delayed\n",
        "import time\n",
        "stime = time.time()\n",
        "batch_datasets = client.list_datasets(sample_id = batch_id)\n",
        "\n",
        "num_cores = os.cpu_count()\n",
        "print(f'{num_cores=}')\n",
        "Parallel(n_jobs=num_cores)(delayed(client.download_dataset)(ds['unique_id'])for ds in batch_datasets)\n",
        "etime = time.time()\n",
        "print(f'Time taken: {etime-stime}')"
      ],
      "metadata": {
        "id": "IFRnziVD3nh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaLEaNny70iC"
      },
      "source": [
        "## Part 3: Working with ScopeFoundry hdf5 files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CLniWAa622z"
      },
      "source": [
        "### Open the file and get your bearings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_5IvGWA622z"
      },
      "outputs": [],
      "source": [
        "# Choose a file to work with\n",
        "sample_file = 'crucible-downloads/yrliu98_S-pMeMBAI-pre-2_1_1_run3_spec_run.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6swDWG3622z"
      },
      "outputs": [],
      "source": [
        "# Opening the file\n",
        "with h5py.File(sample_file, 'r') as f:\n",
        "  # groups within the file object\n",
        "  print(f.keys())\n",
        "\n",
        "  # attributes of the file object (the file object is the \"root group\")\n",
        "  print(f.attrs.keys())\n",
        "\n",
        "  # every group has a name (the name is the key)\n",
        "  for group_name in f:\n",
        "    print(group_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFK80HUN622z"
      },
      "outputs": [],
      "source": [
        "# The App Group\n",
        "\n",
        "with h5py.File(sample_file, 'r') as f:\n",
        "  app = f['app']\n",
        "\n",
        "  # groups within the app group\n",
        "  print(list(app.keys()))\n",
        "\n",
        "  # attributes of the app group\n",
        "  print(list(app.attrs.keys()))\n",
        "\n",
        "  # print the settings group attributes for the app\n",
        "  print(\"\\n\\napp settings: \")\n",
        "  [print(k,v) for k,v in list(app['settings'].attrs.items())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjmuXW-U622z"
      },
      "outputs": [],
      "source": [
        "# The Hardware Group\n",
        "\n",
        "with h5py.File(sample_file, 'r') as f:\n",
        "  hw = f['hardware']\n",
        "\n",
        "  # groups within the hw group\n",
        "  print(list(hw.keys()))\n",
        "\n",
        "  # attributes of the hw group\n",
        "  print(list(hw.attrs.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73qvO3DS6220"
      },
      "outputs": [],
      "source": [
        "# The Measurement Group\n",
        "\n",
        "with h5py.File(sample_file, 'r') as f:\n",
        "  M = f['measurement']\n",
        "\n",
        "  # groups within the measurement group\n",
        "  print(list(M.keys()))\n",
        "\n",
        "  # attributes of the measurement group\n",
        "  print(list(M.attrs.keys()))\n",
        "\n",
        "  # Look at the measurement sub group\n",
        "  # Note that you can keep extending out key values for groups or use a file system like notation\n",
        "  print(list(f['measurement']['spec_run'].keys()))\n",
        "  print(list(f['measurement/spec_run'].keys()))\n",
        "\n",
        "  # Each of the values printed is a Dataset Object that can be accessed as a numpy array\n",
        "  arr = np.array(f['measurement/spec_run/wl_spectra'])\n",
        "  print(arr[0:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8pWckmd6220"
      },
      "source": [
        "### Recurse the file systematically with the ```visititems``` function.\n",
        "Instead of manually recursing the file, we can define a function and pass it to visititems which will recursively call the function on each of the objects in the h5file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDXBlM7l6220"
      },
      "outputs": [],
      "source": [
        "def explore_h5_structure(name, obj):\n",
        "    indent = \"  \" * name.count('/')\n",
        "    if isinstance(obj, h5py.Group):\n",
        "        print(f\"{indent}{name}/ (Group)\")\n",
        "    elif isinstance(obj, h5py.Dataset):\n",
        "        print(f\"{indent}{name} (Dataset) - Shape: {obj.shape}, Type: {obj.dtype}\")\n",
        "\n",
        "with h5py.File(sample_file, 'r') as f:\n",
        "    f.visititems(explore_h5_structure)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gyEdMmF6220"
      },
      "source": [
        "### Extract and plot the PL spectra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7GXcFEP6220"
      },
      "outputs": [],
      "source": [
        "with h5py.File(sample_file, 'r') as h5file:\n",
        "\n",
        "    # extract the corrected PL spectra as an array\n",
        "    pl_spectra = np.array(h5file['measurement/spec_run/pl_spectra_corrected'])\n",
        "\n",
        "    # determine how many spectra were collected\n",
        "    dims = pl_spectra.shape\n",
        "\n",
        "    # extract the wavelengths as an array\n",
        "    wavelengths = np.array(h5file['measurement/spec_run/pl_wls'])\n",
        "\n",
        "    # create the plot\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # for each spectra, plot the line\n",
        "    for i in range(0, dims[0]):\n",
        "        ax.plot(wavelengths, pl_spectra[i], label=f\"Spectrum {i+1}\", linewidth=2, alpha=0.8)\n",
        "\n",
        "    # formatting\n",
        "    ax.set_xlabel('Wavelength (nm)', fontsize=12)\n",
        "    ax.set_ylabel('Intensity', fontsize=12)\n",
        "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMhaYekF6220"
      },
      "source": [
        "### Extract and plot the UV-vis spectra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQ_n1beB6220"
      },
      "outputs": [],
      "source": [
        "with h5py.File(sample_file, 'r') as h5file:\n",
        "\n",
        "    # extract the corrected PL spectra as an array\n",
        "    wl_spectra = np.array(h5file['measurement/spec_run/wl_spectra_corrected'])\n",
        "\n",
        "    # determine how many spectra were collected\n",
        "    dims = wl_spectra.shape\n",
        "\n",
        "    # extract the wavelengths as an array\n",
        "    wavelengths = np.array(h5file['measurement/spec_run/wl_wls'])\n",
        "\n",
        "    # create the plot\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # for each spectra, plot the line\n",
        "    for i in range(0, dims[0]):\n",
        "        ax.plot(wavelengths, wl_spectra[i], label=f\"Spectrum {i+1}\", linewidth=2, alpha=0.8)\n",
        "\n",
        "    # formatting\n",
        "    ax.set_xlabel('Wavelength (nm)', fontsize=12)\n",
        "    ax.set_ylabel('Intensity', fontsize=12)\n",
        "    ax.set_ylim(0,1)\n",
        "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7BqcD1Q6220"
      },
      "source": [
        "### Extract and display the sample image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDJRmqhy6220"
      },
      "outputs": [],
      "source": [
        "with h5py.File(sample_file, 'r') as h5file:\n",
        "\n",
        "    # extract the image\n",
        "    imarray = np.array(h5file['measurement/spec_run/adj_photo'])\n",
        "\n",
        "    # create the plot\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    ax.imshow(imarray, cmap = 'grey')\n",
        "    ax.set_title('Sample Photo', fontsize=14, fontweight='bold')\n",
        "    ax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qmc8y2I6220"
      },
      "source": [
        "## Part 4: Scale this to explore the whole batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYj4Rtuf6220"
      },
      "source": [
        "#### Define functions for extracting the data and creating the plots"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_plots_by_type(plot_type):\n",
        "    \"\"\"Display all samples for a specific plot type\"\"\"\n",
        "    with output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        # Find all samples that have this plot type\n",
        "        samples_with_plot = []\n",
        "        batch_photos = []\n",
        "\n",
        "        for ds in datasets:\n",
        "          if ds.endswith(\"spec_run.h5\"):\n",
        "            with h5py.File(ds) as f:\n",
        "                M = f['measurement/spec_run']\n",
        "                M_keys = list(M.keys())\n",
        "                if plot_type in M_keys:\n",
        "                    samples_with_plot.append(ds)\n",
        "\n",
        "          elif ds.endswith(\".jpg\"):\n",
        "            batch_photos.append(ds)\n",
        "\n",
        "          else:\n",
        "            pass\n",
        "\n",
        "        n_samples = len(samples_with_plot)\n",
        "        fig = plt.figure(figsize=(20, 10))\n",
        "\n",
        "        # Left side: batch photo (takes up left 1/4 of figure)\n",
        "        batch_photo_ax = plt.subplot2grid((1, 4), (0, 0), colspan=1)\n",
        "\n",
        "        # Right side: individual plots (takes up right 3/4 of figure)\n",
        "        plot_cols = min(3, n_samples)\n",
        "        plot_rows = (n_samples + plot_cols - 1) // plot_cols\n",
        "\n",
        "\n",
        "        # Create subplots for individual samples\n",
        "        plot_axes = []\n",
        "        for i in range(n_samples):\n",
        "            row = i // plot_cols\n",
        "            col = i % plot_cols\n",
        "            ax = plt.subplot2grid((plot_rows, plot_cols), (row, col))\n",
        "            # Position these subplots in the right 3/4 of the figure\n",
        "            pos = ax.get_position()\n",
        "            new_pos = [pos.x0 * 0.75 + 0.25, pos.y0, pos.width * 0.75, pos.height]\n",
        "            ax.set_position(new_pos)\n",
        "            plot_axes.append(ax)\n",
        "\n",
        "\n",
        "        if batch_photos:\n",
        "          try:\n",
        "              from PIL import Image\n",
        "              # Use the first batch photo found\n",
        "              batch_img = np.array(Image.open(batch_photos[0]))\n",
        "              batch_photo_ax.imshow(batch_img)\n",
        "              batch_photo_ax.set_title('Batch Photo', fontsize=14, fontweight='bold')\n",
        "              batch_photo_ax.axis('off')\n",
        "          except Exception as e:\n",
        "              batch_photo_ax.text(0.5, 0.5, f'Error loading\\nbatch photo\\n{str(e)[:50]}...',\n",
        "                                  ha='center', va='center', transform=batch_photo_ax.transAxes,\n",
        "                                  fontsize=10)\n",
        "              batch_photo_ax.set_title('Batch Photo (Error)', fontsize=14)\n",
        "              batch_photo_ax.axis('off')\n",
        "        else:\n",
        "          batch_photo_ax.text(0.5, 0.5, 'No batch photo\\nfound',\n",
        "                            ha='center', va='center', transform=batch_photo_ax.transAxes,\n",
        "                            fontsize=12)\n",
        "          #batch_photo_ax.set_title('Batch Photo', fontsize=14, fontweight='bold')\n",
        "          batch_photo_ax.axis('off')\n",
        "\n",
        "\n",
        "        # Plot each sample\n",
        "        for i, ds_file in enumerate(samples_with_plot):\n",
        "            ax = plot_axes[i]\n",
        "            ds_name = os.path.basename(ds_file).split('_spec_run.')[0]\n",
        "\n",
        "            if plot_type == 'adj_photo':\n",
        "                # For photo data, we need to extract the image data\n",
        "                try:\n",
        "                    with h5py.File(ds_file) as f:\n",
        "                        imarray = np.array(f[f'measurement/spec_run/{plot_type}'])\n",
        "\n",
        "                    ax.imshow(imarray, cmap='grey')\n",
        "                    ax.set_title(ds_name, fontsize=11)\n",
        "                    ax.axis('off')\n",
        "\n",
        "                except Exception as e:\n",
        "                    ax.text(0.5, 0.5, f'Error displaying\\n{ds_name}',\n",
        "                           ha='center', va='center', transform=ax.transAxes)\n",
        "                    ax.set_title(f'{ds_name}', fontsize=12)\n",
        "            else:\n",
        "                try:\n",
        "                    with h5py.File(ds_file, 'r') as h5file:\n",
        "                        M = h5file[f\"measurement/spec_run\"]\n",
        "\n",
        "                        if len(M[plot_type]) > 0:\n",
        "                            wl_key = plot_type.split(\"_\")[0] + \"_wls\"\n",
        "                            spectra = np.array(M[plot_type])\n",
        "                            dims = spectra.shape\n",
        "\n",
        "                            wls = np.array(M[wl_key])\n",
        "\n",
        "                            for j in range(0, dims[0]):  # Fixed variable name conflict\n",
        "                                ax.plot(wls, spectra[j], label=f\"Spectrum {j+1}\", linewidth=2, alpha=0.8)\n",
        "\n",
        "                            ax.set_xlabel('Wavelength (nm)', fontsize=12)\n",
        "                            ax.set_ylabel('Intensity', fontsize=12)\n",
        "\n",
        "                            if 'wl' in plot_type:\n",
        "                                ax.set_ylim(0, 1)\n",
        "\n",
        "                            ax.set_title(ds_name, fontsize=11)\n",
        "\n",
        "                            # Adjust legend to fit better in smaller subplots\n",
        "                            if dims[0] > 1 and dims[0] <= 3:\n",
        "                                ax.legend(fontsize=8, loc='best')\n",
        "\n",
        "                            ax.grid(True, alpha=0.3)\n",
        "\n",
        "                except Exception as e:\n",
        "                    ax.text(0.5, 0.5, f'Error displaying\\n{ds_name}',\n",
        "                           ha='center', va='center', transform=ax.transAxes)\n",
        "                    ax.set_title(f'{ds_name}', fontsize=12)\n",
        "\n",
        "       # plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "umw_ISDTth8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlU6hRIL6221"
      },
      "source": [
        "### Explore the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSV01qss6221"
      },
      "outputs": [],
      "source": [
        "# Data Files\n",
        "datasets = []\n",
        "for ds in batch_datasets:\n",
        "    ds_file = os.path.basename(ds['file_to_upload'])\n",
        "    local_ds_path = os.path.join(f'crucible-downloads/{ds_file}')\n",
        "    datasets.append(local_ds_path)\n",
        "\n",
        "# Plot Options\n",
        "plot_types_available = ['adj_photo', 'wl_spectra_corrected', 'pl_spectra_corrected']\n",
        "\n",
        "\n",
        "# Create the interactive widget\n",
        "plot_type_dropdown = widgets.Dropdown(\n",
        "    options=plot_types_available,\n",
        "    value=plot_types_available[0] if plot_types_available else None,\n",
        "    description='Plot Type:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_plot_type_change(change):\n",
        "    display_plots_by_type(change['new'])\n",
        "\n",
        "plot_type_dropdown.observe(on_plot_type_change, names='value')\n",
        "\n",
        "display(plot_type_dropdown)\n",
        "display(output)\n",
        "\n",
        "\n",
        "display_plots_by_type(plot_types_available[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZn5ieGVUsg7"
      },
      "source": [
        "###  Part 4: Play around and see what else you can do with the API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjcKcCRPUsg7"
      },
      "source": [
        "#### Add a project you are working on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uMDP1vGUsg7"
      },
      "outputs": [],
      "source": [
        "help(client.add_project)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QmoASXYUsg7"
      },
      "outputs": [],
      "source": [
        "client.add_project(project_info = {\"project_id\":\"AUM_DEMO\",\n",
        "                                   \"organization\":\"Summer School\",\n",
        "                                   \"project_lead_email\":\"mkwall@lbl.gov\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6Fkb0_1Usg7"
      },
      "source": [
        "#### Add a sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9L-4rdo8X8q"
      },
      "outputs": [],
      "source": [
        "sample = client.add_sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THLhi7sd8a4X"
      },
      "source": [
        "#### Add a dataset from your google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kngvnFsu8gvw"
      },
      "outputs": [],
      "source": [
        "# mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJOrjY-nUsg7"
      },
      "outputs": [],
      "source": [
        "# choose a file\n",
        "your_file_path = \"sample_data/california_housing_train.csv\"\n",
        "\n",
        "# define some metadata you want to add to this dataset\n",
        "metadata_to_add = {'comments': 'this is a fake dataset',\n",
        "                   'weather': 'sunny',\n",
        "                   'iphone_version': 11\n",
        "                  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZ1xOPQ0Usg7"
      },
      "outputs": [],
      "source": [
        "# fill out the fields and send the data to Crucible\n",
        "results = client.build_new_dataset_from_file(files_to_upload = [your_file_path],\n",
        "                                        dataset_name = None, # this will default to the file name\n",
        "                                        project_id = None, # this will default to unknown\n",
        "                                        instrument_name = None, # default is null\n",
        "                                        measurement = None, # default is null\n",
        "                                        session_name = None, # default is null\n",
        "                                        source_folder = None, # this will default to the base directory\n",
        "                                        scientific_metadata = metadata_to_add, # this is the dictionary you defined above\n",
        "                                        keywords = [], # list any keywords you want to be able to search on\n",
        "                                        ingestor = 'CrucibleDatasetIngestor', # use a generic ingestor\n",
        "                                        verbose = False,\n",
        "                                        wait_for_ingestion_response = True)\n",
        "\n",
        "ds = results['created_record']\n",
        "pprint.pprint(ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fIC3B0TUsg7"
      },
      "source": [
        "#### Associate this dataset with the sample you created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_pubuDVUsg7"
      },
      "outputs": [],
      "source": [
        "# define the dataset and sample\n",
        "dataset_id = ds['unique_id']\n",
        "sample_id = sample['unique_id']\n",
        "\n",
        "# link them!\n",
        "client.add_dataset_to_sample(dataset_id = dataset_id, sample_id = sample_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5UttaWSUsg8"
      },
      "outputs": [],
      "source": [
        "# see all the datasets associated with your sample\n",
        "client.list_datasets(sample_id = sample_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8K9JcCZ9sdX"
      },
      "source": [
        "#### Send your dataset from Crucible to SciCat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsL0L90KUsg7"
      },
      "outputs": [],
      "source": [
        "client.send_to_scicat(dsid = ds['unique_id'], wait_for_scicat_response= True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVQiRWYmUsg7"
      },
      "source": [
        "Go to https://mf-scicat.lbl.gov to get a quick look at your data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Ajyxgack6P7s",
        "8CLniWAa622z",
        "S8pWckmd6220",
        "0gyEdMmF6220",
        "XMhaYekF6220",
        "s7BqcD1Q6220",
        "DZn5ieGVUsg7"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}